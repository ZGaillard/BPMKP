{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b62077fbcab52b",
   "metadata": {},
   "source": [
    "# Branch-and-Price Benchmark Readout\n",
    "\n",
    "These notes accompany the project report in `README.md` and track how I looked at the benchmark CSVs produced by the branch-and-price solver for the multiple knapsack problem (MKP).\n",
    "- Uses the CSVs emitted by `mvn exec:java -Dexec.mainClass=ca.udem.gaillarz.benchmark.MainBenchmark`.\n",
    "- Plots and tables are written to `analysis_out/` so I can drop them into the write-up.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04d568d236066c",
   "metadata": {},
   "source": [
    "## How I ran the benchmarks\n",
    "- Input folder defaults to `benchmark_results/`; right now it contains the SMALL batch (`SMALL_results.csv`).\n",
    "- The notebook will pick up additional FK_* sets automatically;\n",
    "- Everything is pure Python + pandas/NumPy/Matplotlib to keep dependencies light.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbf0c5ebcdd2897",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CSVs in /home/zakary/Main/uni/maitrise/or/BPMKP/benchmark_results\n",
      "Saving figures/tables in /home/zakary/Main/uni/maitrise/or/BPMKP/analysis_out\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# None means: discover any CSVs under BASE_DIR. Otherwise, set to [\"SMALL\", \"FK_1\", ...]\n",
    "DATASETS = None\n",
    "\n",
    "BASE_DIR = Path(\"./benchmark_results\")\n",
    "CSV_GLOBS = [\"*results*.csv\", \"*.csv\"]\n",
    "\n",
    "OUT_DIR = Path(\"analysis_out\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Looking for CSVs in {BASE_DIR.resolve()}\")\n",
    "print(f\"Saving figures/tables in {OUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51baf95f4f93964",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError as exc:\n",
    "    raise SystemExit(\"Install pandas, numpy, matplotlib (pip install pandas numpy matplotlib).\") from exc\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5de3d9f468d9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 179 rows from /home/zakary/Main/uni/maitrise/or/BPMKP/benchmark_results/SMALL_results.csv as dataset='SMALL'\n",
      "Datasets in scope: ['SMALL']\n",
      "Total rows: 179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>dataset</th>\n",
       "      <th>items</th>\n",
       "      <th>knapsacks</th>\n",
       "      <th>status</th>\n",
       "      <th>objective</th>\n",
       "      <th>bound</th>\n",
       "      <th>gap</th>\n",
       "      <th>nodes</th>\n",
       "      <th>time</th>\n",
       "      <th>optimal</th>\n",
       "      <th>error</th>\n",
       "      <th>source_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed01.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>GAP_LIMIT</td>\n",
       "      <td>9114.0</td>\n",
       "      <td>9128.0</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed02.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>GAP_LIMIT</td>\n",
       "      <td>8727.0</td>\n",
       "      <td>8769.0</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed03.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>6346.0</td>\n",
       "      <td>6346.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed04.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed05.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   instance dataset  items  knapsacks  \\\n",
       "0  probT1_0U_R50_T002_M010_N0020_seed01.txt   SMALL     20         10   \n",
       "1  probT1_0U_R50_T002_M010_N0020_seed02.txt   SMALL     20         10   \n",
       "2  probT1_0U_R50_T002_M010_N0020_seed03.txt   SMALL     20         10   \n",
       "3  probT1_0U_R50_T002_M010_N0020_seed04.txt   SMALL     20         10   \n",
       "4  probT1_0U_R50_T002_M010_N0020_seed05.txt   SMALL     20         10   \n",
       "\n",
       "      status  objective   bound       gap  nodes   time  optimal  error  \\\n",
       "0  GAP_LIMIT     9114.0  9128.0  0.001534      2  0.196    False    NaN   \n",
       "1  GAP_LIMIT     8727.0  8769.0  0.004790      3  0.101    False    NaN   \n",
       "2    OPTIMAL     6346.0  6346.0  0.000000      2  0.042     True    NaN   \n",
       "3    OPTIMAL     7626.0  7626.0  0.000000      1  0.015     True    NaN   \n",
       "4    OPTIMAL     6782.0  6782.0  0.000000      1  0.042     True    NaN   \n",
       "\n",
       "                                          source_csv  \n",
       "0  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  \n",
       "1  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  \n",
       "2  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  \n",
       "3  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  \n",
       "4  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "def candidate_csvs(base_dir: Path, patterns: Iterable[str]) -> list[Path]:\n",
    "    paths: list[Path] = []\n",
    "    for pat in patterns:\n",
    "        paths.extend(base_dir.glob(f\"**/{pat}\"))\n",
    "    return sorted({p.resolve() for p in paths if p.is_file()})\n",
    "\n",
    "\n",
    "def guess_dataset_name(path: Path) -> str:\n",
    "    stem = path.stem\n",
    "    if \"_results\" in stem:\n",
    "        stem = stem.split(\"_results\")[0]\n",
    "    if path.parent != BASE_DIR:\n",
    "        return path.parent.name.upper()\n",
    "    return stem.upper()\n",
    "\n",
    "\n",
    "def load_csv(path: Path, dataset_label: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"dataset\" not in df.columns and \"set\" in df.columns:\n",
    "        df = df.rename(columns={\"set\": \"dataset\"})\n",
    "    df[\"dataset\"] = df.get(\"dataset\", dataset_label).astype(str).str.upper()\n",
    "    df[\"source_csv\"] = str(path)\n",
    "    return df\n",
    "\n",
    "all_csvs: list[tuple[Path, str]] = []\n",
    "if DATASETS:\n",
    "    for ds in DATASETS:\n",
    "        ds_path = BASE_DIR / ds\n",
    "        if ds_path.is_dir():\n",
    "            matches = candidate_csvs(ds_path, CSV_GLOBS)\n",
    "        else:\n",
    "            matches = candidate_csvs(BASE_DIR, [f\"{ds}*.csv\"])\n",
    "        all_csvs.extend((p, ds.upper()) for p in matches)\n",
    "else:\n",
    "    all_csvs = [(p, guess_dataset_name(p)) for p in candidate_csvs(BASE_DIR, CSV_GLOBS)]\n",
    "\n",
    "frames = []\n",
    "for path, label in all_csvs:\n",
    "    try:\n",
    "        df_part = load_csv(path, label)\n",
    "        frames.append(df_part)\n",
    "        print(f\"Loaded {len(df_part)} rows from {path} as dataset='{df_part['dataset'].iloc[0]}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Skipped {path}: {e}\")\n",
    "\n",
    "if not frames:\n",
    "    raise RuntimeError(\"No CSV files found; check BASE_DIR or DATASETS selection.\")\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "dataset_names = sorted(df[\"dataset\"].unique())\n",
    "print(f\"Datasets in scope: {dataset_names}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491beb08604bafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with missing numeric fields.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>dataset</th>\n",
       "      <th>items</th>\n",
       "      <th>knapsacks</th>\n",
       "      <th>status</th>\n",
       "      <th>objective</th>\n",
       "      <th>bound</th>\n",
       "      <th>gap</th>\n",
       "      <th>nodes</th>\n",
       "      <th>time</th>\n",
       "      <th>optimal</th>\n",
       "      <th>error</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed01.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>GAP_LIMIT</td>\n",
       "      <td>9114.0</td>\n",
       "      <td>9128.0</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "      <td>20 items / 10 knapsacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed02.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>GAP_LIMIT</td>\n",
       "      <td>8727.0</td>\n",
       "      <td>8769.0</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "      <td>20 items / 10 knapsacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed03.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>6346.0</td>\n",
       "      <td>6346.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "      <td>20 items / 10 knapsacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed04.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "      <td>20 items / 10 knapsacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>probT1_0U_R50_T002_M010_N0020_seed05.txt</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>OPTIMAL</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/zakary/Main/uni/maitrise/or/BPMKP/benchm...</td>\n",
       "      <td>20 items / 10 knapsacks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   instance dataset  items  knapsacks  \\\n",
       "0  probT1_0U_R50_T002_M010_N0020_seed01.txt   SMALL     20         10   \n",
       "1  probT1_0U_R50_T002_M010_N0020_seed02.txt   SMALL     20         10   \n",
       "2  probT1_0U_R50_T002_M010_N0020_seed03.txt   SMALL     20         10   \n",
       "3  probT1_0U_R50_T002_M010_N0020_seed04.txt   SMALL     20         10   \n",
       "4  probT1_0U_R50_T002_M010_N0020_seed05.txt   SMALL     20         10   \n",
       "\n",
       "      status  objective   bound       gap  nodes   time  optimal  error  \\\n",
       "0  GAP_LIMIT     9114.0  9128.0  0.001534      2  0.196    False    NaN   \n",
       "1  GAP_LIMIT     8727.0  8769.0  0.004790      3  0.101    False    NaN   \n",
       "2    OPTIMAL     6346.0  6346.0  0.000000      2  0.042     True    NaN   \n",
       "3    OPTIMAL     7626.0  7626.0  0.000000      1  0.015     True    NaN   \n",
       "4    OPTIMAL     6782.0  6782.0  0.000000      1  0.042     True    NaN   \n",
       "\n",
       "                                          source_csv                    group  \n",
       "0  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  20 items / 10 knapsacks  \n",
       "1  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  20 items / 10 knapsacks  \n",
       "2  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  20 items / 10 knapsacks  \n",
       "3  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  20 items / 10 knapsacks  \n",
       "4  /home/zakary/Main/uni/maitrise/or/BPMKP/benchm...  20 items / 10 knapsacks  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema checks & normalization\n",
    "required_cols = [\"time\", \"nodes\", \"items\", \"knapsacks\", \"status\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}. Found columns: {list(df.columns)}\")\n",
    "\n",
    "optional_cols = [\"gap\", \"objective\", \"bound\"]\n",
    "\n",
    "# Normalize types\n",
    "for c in [\"time\", \"nodes\", \"items\", \"knapsacks\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in optional_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"status\"] = df[\"status\"].astype(str).str.upper()\n",
    "df[\"dataset\"] = df[\"dataset\"].astype(str)\n",
    "df[\"optimal\"] = df[\"status\"].eq(\"OPTIMAL\")\n",
    "\n",
    "df[\"group\"] = (\n",
    "    df[\"items\"].astype(\"Int64\").astype(str)\n",
    "    + \" items / \"\n",
    "    + df[\"knapsacks\"].astype(\"Int64\").astype(str)\n",
    "    + \" knapsacks\"\n",
    ")\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"time\", \"nodes\", \"items\", \"knapsacks\"])\n",
    "after = len(df)\n",
    "print(f\"Dropped {before-after} rows with missing numeric fields.\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d1845e8381f3b",
   "metadata": {},
   "source": [
    "## Quick headline numbers\n",
    "A short, human-friendly readout so I can reference the key figures directly in the written report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e9bf775b542a75",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 20) (2602546737.py, line 20)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mMarkdown(\"\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 20)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "opt_pct = 100 * df[\"optimal\"].mean()\n",
    "median_time = df[\"time\"].median()\n",
    "p90_time = df[\"time\"].quantile(0.9)\n",
    "max_time_row = df.loc[df[\"time\"].idxmax()]\n",
    "nodes_median = df[\"nodes\"].median()\n",
    "nodes_max = df[\"nodes\"].max()\n",
    "\n",
    "notes = [\n",
    "    f\"- {len(df)} runs across {len(dataset_names)} dataset(s): {', '.join(dataset_names)}.\",\n",
    "    f\"- Optimal in {opt_pct:.1f}% of cases; median runtime {median_time:.3f}s (p90 {p90_time:.3f}s).\",\n",
    "    f\"- Longest run: {max_time_row['time']:.3f}s on {max_time_row.get('dataset', '?')} / {max_time_row.get('instance', 'unknown instance')}.\",\n",
    "    f\"- Search effort stays shallow: median nodes {nodes_median:.0f}, max {nodes_max}.\",\n",
    "]\n",
    "\n",
    "if \"gap\" in df.columns:\n",
    "    notes.append(f\"- Gaps stay modest (max gap {df['gap'].max():.4f}).\")\n",
    "\n",
    "Markdown(\"\n",
    "\".join(notes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c4c8c0d6a7ce1",
   "metadata": {},
   "source": [
    "## Summaries\n",
    "Per-status, per-dataset, and per-size-group tables that feed both the plots and the README narrative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1816d7dc1f5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(s, p):\n",
    "    return float(np.quantile(s, p)) if len(s) else np.nan\n",
    "\n",
    "status_summary = (\n",
    "    df.groupby(\"status\", dropna=False)\n",
    "    .agg(\n",
    "        n=(\"time\", \"size\"),\n",
    "        time_median=(\"time\", \"median\"),\n",
    "        time_mean=(\"time\", \"mean\"),\n",
    "        time_p90=(\"time\", lambda s: q(s, 0.9)),\n",
    "        nodes_median=(\"nodes\", \"median\"),\n",
    "        nodes_mean=(\"nodes\", \"mean\"),\n",
    "        optimal_rate=(\"optimal\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"n\", \"time_mean\"], ascending=[False, False])\n",
    ")\n",
    "\n",
    "# Dataset summary\n",
    "\n",
    "dataset_summary = (\n",
    "    df.groupby(\"dataset\", dropna=False)\n",
    "    .agg(\n",
    "        n=(\"time\", \"size\"),\n",
    "        time_median=(\"time\", \"median\"),\n",
    "        time_mean=(\"time\", \"mean\"),\n",
    "        time_p90=(\"time\", lambda s: q(s, 0.9)),\n",
    "        time_max=(\"time\", \"max\"),\n",
    "        nodes_median=(\"nodes\", \"median\"),\n",
    "        nodes_mean=(\"nodes\", \"mean\"),\n",
    "        optimal_rate=(\"optimal\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"dataset\")\n",
    ")\n",
    "\n",
    "# Dataset × status summary\n",
    "\n",
    "dataset_status_summary = (\n",
    "    df.groupby([\"dataset\", \"status\"], dropna=False)\n",
    "    .agg(\n",
    "        n=(\"time\", \"size\"),\n",
    "        time_median=(\"time\", \"median\"),\n",
    "        time_mean=(\"time\", \"mean\"),\n",
    "        nodes_median=(\"nodes\", \"median\"),\n",
    "        optimal_rate=(\"optimal\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"dataset\", \"n\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# Size-group summary (within dataset)\n",
    "\n",
    "group_summary = (\n",
    "    df.groupby([\"dataset\", \"group\"], dropna=False)\n",
    "    .agg(\n",
    "        n=(\"time\", \"size\"),\n",
    "        time_min=(\"time\", \"min\"),\n",
    "        time_median=(\"time\", \"median\"),\n",
    "        time_mean=(\"time\", \"mean\"),\n",
    "        time_p90=(\"time\", lambda s: q(s, 0.9)),\n",
    "        time_max=(\"time\", \"max\"),\n",
    "        nodes_median=(\"nodes\", \"median\"),\n",
    "        nodes_mean=(\"nodes\", \"mean\"),\n",
    "        optimal_rate=(\"optimal\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"dataset\", \"time_mean\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "status_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68611dab54787b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86efbba53aec65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_status_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abae8dc379d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardest size groups per dataset (by mean time)\n",
    "(\n",
    "    group_summary.groupby(\"dataset\", as_index=False)\n",
    "    .apply(lambda g: g.sort_values(\"time_mean\", ascending=False).head(10))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6f62e6b95b13c",
   "metadata": {},
   "source": [
    "## Correlations with runtime (Spearman)\n",
    "A quick check of what moves runtime the most. Positive means longer runtime when the feature increases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d0f610b090dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"nodes\", \"items\", \"knapsacks\"] + [c for c in [\"gap\", \"objective\", \"bound\"] if c in df.columns]\n",
    "\n",
    "corr_rows = []\n",
    "for f in features:\n",
    "    rho = df[[f, \"time\"]].corr(method=\"spearman\").iloc[0, 1]\n",
    "    corr_rows.append({\"feature\": f, \"spearman_rho\": float(rho)})\n",
    "\n",
    "corr_df = pd.DataFrame(corr_rows).sort_values(\"spearman_rho\", ascending=False)\n",
    "corr_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ba332da518a86",
   "metadata": {},
   "source": [
    "## Plots\n",
    "All plots are saved to `analysis_out/` for the report. Runtimes are shown on log scale to make the heavy tails visible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324172c9d03ed4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime vs nodes (log y)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df[\"nodes\"], df[\"time\"], s=12, alpha=0.7)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Nodes explored\")\n",
    "plt.ylabel(\"Runtime (s) [log scale]\")\n",
    "plt.title(\"Runtime vs nodes explored\")\n",
    "plt.tight_layout()\n",
    "p = OUT_DIR / \"runtime_vs_nodes.png\"\n",
    "plt.savefig(p, dpi=200)\n",
    "plt.show()\n",
    "print(\"Saved:\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e054349434622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime distribution by status (log y)\n",
    "statuses = list(status_summary[\"status\"])\n",
    "data = [df.loc[df[\"status\"] == s, \"time\"].values for s in statuses]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(data, labels=statuses, showfliers=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Runtime (s) [log scale]\")\n",
    "plt.title(\"Runtime distribution by status\")\n",
    "plt.xticks(rotation=25, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "p = OUT_DIR / \"runtime_by_status.png\"\n",
    "plt.savefig(p, dpi=200)\n",
    "plt.show()\n",
    "print(\"Saved:\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7fc69c4fc8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime distribution by (items, knapsacks) group (log y), per dataset\n",
    "for ds in dataset_names:\n",
    "    sub = df[df[\"dataset\"] == ds].copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    g_order = sub.groupby(\"group\")[\"time\"].median().sort_values().index.tolist()\n",
    "    data = [sub.loc[sub[\"group\"] == g, \"time\"].values for g in g_order]\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.boxplot(data, labels=g_order, showfliers=False)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Runtime (s) [log scale]\")\n",
    "    plt.title(f\"Runtime distribution by instance size — {ds}\")\n",
    "    plt.xticks(rotation=25, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    p = OUT_DIR / f\"runtime_by_group_{ds}.png\"\n",
    "    plt.savefig(p, dpi=200)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d072736c6dd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime distribution by dataset (log y)\n",
    "ds_order = df.groupby(\"dataset\")[\"time\"].median().sort_values().index.tolist()\n",
    "data = [df.loc[df[\"dataset\"] == ds, \"time\"].values for ds in ds_order]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(data, labels=ds_order, showfliers=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Runtime (s) [log scale]\")\n",
    "plt.title(\"Runtime distribution by dataset\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "p = OUT_DIR / \"runtime_by_dataset.png\"\n",
    "plt.savefig(p, dpi=200)\n",
    "plt.show()\n",
    "print(\"Saved:\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4220c3a1fb75",
   "metadata": {},
   "source": [
    "## Export summary tables\n",
    "So I can cite numbers in the README without re-running cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840109b68c1d39b8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "status_summary.to_csv(OUT_DIR / \"status_summary.csv\", index=False)\n",
    "dataset_summary.to_csv(OUT_DIR / \"dataset_summary.csv\", index=False)\n",
    "dataset_status_summary.to_csv(OUT_DIR / \"dataset_status_summary.csv\", index=False)\n",
    "group_summary.to_csv(OUT_DIR / \"group_summary.csv\", index=False)\n",
    "\n",
    "print(\"Wrote:\")\n",
    "for f in [\"status_summary.csv\", \"dataset_summary.csv\", \"dataset_status_summary.csv\", \"group_summary.csv\"]:\n",
    "    print(\" -\", OUT_DIR / f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4148dabbd5929",
   "metadata": {},
   "source": [
    "## Notes for my report\n",
    "- SMALL set: 179 runs, with 58–59% solved to proven optimality. The rest hit the gap threshold quickly (median < 1s), so the solver is keeping gaps tiny even when stopping early.\n",
    "- Runtime tail: one outlier run at ~221s; otherwise p90 is well under a second. Boxplots make this clear.\n",
    "- Search effort: median node count is 3 with a max of 651, which matches the design goal of strong root relaxations plus light branching.\n",
    "- If I add FK_* data later, I’ll drop the new plots/tables into the README as “extended benchmarks.”\n",
    "- For future work, I’d log column-generation stats (columns added, dual stability) to explain the few hard cases instead of only looking at node counts.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
